{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What is image caption?</h3>\n",
    "<p>簡單來說就是「給機器一張圖，機器會輸出一段文字來描述這張圖」</p>\n",
    "\n",
    "步驟如下:\n",
    "1. 準備圖片與文字資料\n",
    " * 圖片:load images、resize image、normalization\n",
    " * 文字:tokenizer、create dictionary、sequence padding、\n",
    " * 將資料分成train、val和test\n",
    " * 資料分段 batch size\n",
    "\n",
    "2. Model\n",
    " * CNN: feature extract、\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yan_Ling\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation, Dropout, Input\n",
    "from keras.layers import Conv2D,MaxPool2D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import tensorflow.contrib.layers as layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "CNN可按照喜好使用vgg16、vgg19、resnet50、inception...等，已被train好的模型，這裡將使用vgg16。\n",
    "\"\"\"\n",
    "\n",
    "# 載入CNN Model as Encoder\n",
    "1. 用tensorflow手刻模型\n",
    "2. 用Keras直接載入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow 手刻\n",
    "batch_size = 32\n",
    "image_shape = [224,224,3]\n",
    "\n",
    "kernel_size = (3,3)\n",
    "strides = (1,1)\n",
    "\n",
    "images=tf.placeholder(tf.float32, shape= [batch_size] + image_shape) # image_shape = [224,224,3]\n",
    "\n",
    "with tf.variable_scope(\"vgg16\"):\n",
    "    conv1_1_feats = tf.layers.conv2d(images, 64, kernel_size, strides, padding ='same', \n",
    "                                     activation =tf.nn.relu, use_bias = True, \n",
    "                                     name = 'conv1_1')\n",
    "    conv1_2_feats = tf.layers.conv2d(conv1_1_feats, 64, kernel_size, strides, padding ='same', \n",
    "                                     activation =tf.nn.relu, use_bias = True, \n",
    "                                     name = 'conv1_2')\n",
    "    pool1_feats = tf.layers.max_pooling2d(conv1_2_feats, pool_size=2, strides=2, name = 'pool1')\n",
    "\n",
    "    conv2_1_feats = tf.layers.conv2d(pool1_feats, 128, kernel_size, strides, padding ='same', \n",
    "                                     activation =tf.nn.relu, use_bias = True, \n",
    "                                     name = 'conv2_1')\n",
    "    conv2_2_feats = tf.layers.conv2d(conv2_1_feats, 128,kernel_size, strides, padding ='same', \n",
    "                                     activation =tf.nn.relu, use_bias = True, \n",
    "                                     name = 'conv2_2')\n",
    "    pool2_feats = tf.layers.max_pooling2d(conv2_2_feats, pool_size=2, strides =2, name = 'pool2')\n",
    "\n",
    "    conv3_1_feats = tf.layers.conv2d(pool2_feats, 256, kernel_size, strides, padding ='same', \n",
    "                                     activation =tf.nn.relu, use_bias = True, \n",
    "                                     name = 'conv3_1')\n",
    "    conv3_2_feats = tf.layers.conv2d(conv3_1_feats, 256, kernel_size, strides, padding ='same', activation =tf.nn.relu, use_bias = True, name = 'conv3_2')\n",
    "    conv3_3_feats = tf.layers.conv2d(conv3_2_feats, 256, kernel_size, strides, padding ='same', activation =tf.nn.relu, use_bias = True, name = 'conv3_3')\n",
    "    pool3_feats = tf.layers.max_pooling2d(conv3_3_feats, pool_size=2, strides =2, name = 'pool3')\n",
    "\n",
    "    conv4_1_feats = tf.layers.conv2d(pool3_feats, 512, kernel_size, strides, padding ='same', activation =tf.nn.relu, use_bias = True, name = 'conv4_1')\n",
    "    conv4_2_feats = tf.layers.conv2d(conv4_1_feats, 512, kernel_size, strides, padding ='same', activation =tf.nn.relu, use_bias = True, name = 'conv4_2')\n",
    "    conv4_3_feats = tf.layers.conv2d(conv4_2_feats, 512, kernel_size, strides, padding ='same', activation =tf.nn.relu, use_bias = True, name = 'conv4_3')\n",
    "    pool4_feats = tf.layers.max_pooling2d(conv4_3_feats, pool_size=2, strides =2, name = 'pool4')\n",
    "\n",
    "    conv5_1_feats = tf.layers.conv2d(pool4_feats, 512, kernel_size, strides, padding ='same', activation =tf.nn.relu, use_bias = True, name = 'conv5_1')\n",
    "    conv5_2_feats = tf.layers.conv2d(conv5_1_feats, 512, kernel_size, strides, padding ='same', activation =tf.nn.relu, use_bias = True, name = 'conv5_2')\n",
    "    conv5_3_feats = tf.layers.conv2d(conv5_2_feats, 512, kernel_size, strides, padding ='same', activation =tf.nn.relu, use_bias = True, name = 'conv5_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_conv5_3_feats = tf.reshape(conv5_3_feats,[batch_size, 196, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用 keras 載入模型\n",
    "image_model = tf.keras.applications.VGG16(include_top=False, \n",
    "                                                weights='imagenet')\n",
    "new_input = image_model.input\n",
    "hidden_layer = image_model.layers[-1].output\n",
    "\n",
    "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)\n",
    "\n",
    "# reshaped_feats = tf.reshape(hidden_layer,(32,196,512))\n",
    "# reshaped_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>RNN Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "dim_embedding = 512\n",
    "max_caption_length = 20\n",
    "\n",
    "num_lstm_units = 512\n",
    "vocabulary_size = 5000\n",
    "\n",
    "num_ctx = 196 # 有196個context vector，每一張圖萃取出196個region，每一個region用一個vector表示\n",
    "dim_ctx = 512 \n",
    "\n",
    "fc_drop_rate = 0.5\n",
    "lstm_drop_rate = 0.3\n",
    "attention_loss_factor = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_kernel_initializer_scale = 0.08\n",
    "fc_kernel_initializer = tf.random_uniform_initializer(\n",
    "            minval = -fc_kernel_initializer_scale,\n",
    "            maxval = fc_kernel_initializer_scale)\n",
    "\n",
    "is_train = True\n",
    "\n",
    "fc_kernel_regularizer_scale = 1e-4\n",
    "if is_train and fc_kernel_regularizer_scale > 0:\n",
    "    fc_kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = fc_kernel_regularizer_scale)\n",
    "else:\n",
    "    fc_kernel_regularizer = None\n",
    "    \n",
    "\n",
    "# activity_regularizer = tf.contrib.layers.l1_regularizer(scale = 0.0, scope = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feats = reshaped_conv5_3_feats\n",
    "contexts = conv_feats\n",
    "sentences = tf.placeholder(dtype=tf.int32, \n",
    "                           shape=[batch_size, max_caption_length]) # 32 * 20\n",
    "masks = tf.placeholder(dtype=tf.float32, \n",
    "                       shape=[batch_size, max_caption_length]) # 32 * 20\n",
    "\n",
    "last_memory = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[batch_size, num_lstm_units]) # 32 * 512\n",
    "\n",
    "last_output = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[batch_size, num_lstm_units]) # 32 * 512\n",
    "\n",
    "last_word = tf.placeholder(\n",
    "    dtype=tf.int32,\n",
    "    shape=[batch_size]) # 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"以context_mean來初始化\"\"\"\n",
    "def initialize(cont_mean):\n",
    "    context_mean = tf.layers.dropout(inputs = cont_mean, rate = fc_drop_rate, training = is_train)\n",
    "    ##fc_drop_rate = 0.5;is_train = True\n",
    "    memory = tf.layers.dense(cont_mean, units=num_lstm_units,\n",
    "                             activation = None,\n",
    "                             use_bias = True,\n",
    "                             trainable = is_train,\n",
    "                             activity_regularizer = None)\n",
    "                           \n",
    "    output = tf.layers.dense(cont_mean,\n",
    "                           units=num_lstm_units,\n",
    "                           activation=None,\n",
    "                           use_bias = True,\n",
    "                           trainable = is_train,\n",
    "                           activity_regularizer = None)\n",
    "    return memory, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention\n",
    "\"\"\"\n",
    "1. calculate match score\n",
    "2. put match score into softmax layer to obtain alpha (seen as probability)\n",
    "\n",
    "contexts = conv_feats\n",
    "維度為 32 x 196 x 512 \n",
    "\n",
    "output 是 last output\n",
    "維度為 32 * 512\n",
    "\"\"\"\n",
    "\n",
    "def attend(contexts, output):\n",
    "    reshaped_context = tf.reshape(contexts, [-1,dim_ctx]) # 6272 * 512\n",
    "    reshaped_context = tf.layers.dropout(reshaped_context, \n",
    "                                      rate = fc_drop_rate)\n",
    "    output = tf.layers.dropout(output, fc_drop_rate) # 32 * 512\n",
    "  \n",
    "    logits1 = tf.layers.dense(reshaped_context, \n",
    "                           units = 1,\n",
    "                           activation = None,\n",
    "                           use_bias = False)\n",
    "                            # after shape 6272 * 1\n",
    "    logits1 = tf.reshape(logits1, [-1, num_ctx]) #  32 * 196\n",
    "  \n",
    "    logits2 = tf.layers.dense(output, \n",
    "                           units = num_ctx, \n",
    "                           activation = None,\n",
    "                           use_bias = False) #  32 * 196\n",
    "    logits = logits1 + logits2 # 32 * 196\n",
    "  \n",
    "    alpha = tf.nn.softmax(logits) # 32 * 196\n",
    "  \n",
    "    return alpha # 32 * 196\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(expanded_output):\n",
    "    \"\"\" Decode the expanded output of the LSTM into a word. \"\"\"\n",
    "    expanded_output = tf.layers.dropout(expanded_output)\n",
    " \n",
    "    logits = tf.layers.dense(expanded_output,\n",
    "                               units = vocabulary_size,\n",
    "                               activation = None,\n",
    "                               name = 'fc')\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('word_embedding'):\n",
    "    embedding_matrix = tf.get_variable(shape=[vocab_size,dim_embedding],\n",
    "                                    initializer=fc_kernel_initializer,                                    \n",
    "                                    trainable=is_train,\n",
    "                                    name = 'weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.nn.rnn_cell.LSTMCell(\n",
    "            num_lstm_units,\n",
    "            initializer=fc_kernel_initializer)\n",
    "\n",
    "lstm = tf.nn.rnn_cell.DropoutWrapper(lstm,\n",
    "      input_keep_prob=1.0 -lstm_drop_rate,\n",
    "      output_keep_prob=1.0 - lstm_drop_rate,\n",
    "      state_keep_prob=1.0 - lstm_drop_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LSTM using the mean context\n",
    "with tf.variable_scope(\"initialize\"):\n",
    "#     context_mean = tf.reduce_mean(conv_feats, axis=1) # after shape 32 * 512\n",
    "    initial_memory, initial_output = initialize(tf.reduce_mean(conv_feats, axis=1))\n",
    "    initial_state = initial_memory, initial_output # 32 * 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to run\n",
    "predictions = []\n",
    "\n",
    "alphas = []\n",
    "cross_entropies = []\n",
    "predictions_correct = []\n",
    "num_steps = max_caption_length\n",
    "last_output = initial_output # 把初始化的output當成上一步的output\n",
    "last_memory = initial_memory # 初始化的memory當作上一步的memory\n",
    "last_word = tf.zeros([batch_size], tf.int32) # 上一步輸出的詞彙\n",
    "\n",
    "    \n",
    "last_state = last_memory, last_output # 上一個cell的狀態為tuple (last_memory, last_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每一句有20個字, num_steps＝20\n",
    "\"\"\"\n",
    "1. 丟進attention，得到masked_alpha值 \n",
    "2. 透過查找embedding_matrix，找到上一個字的word vector\n",
    "3. 丟進lstm\n",
    "\"\"\"\n",
    "for idx in range(num_steps):\n",
    "  # Attention Mechanism\n",
    "  with tf.variable_scope('attend', reuse=tf.AUTO_REUSE) as scope:\n",
    "\n",
    "    alpha = attend(contexts, last_output)\n",
    "    \"\"\"attention的第三個步驟： \n",
    "    contexts shape == 32 * 196 * 512; \n",
    "    alpha shape == 32 * 196\n",
    "    alpha擴展第三個維度 ＝＝ (32*196*1)\n",
    "    將alpha值乘上 contexts\n",
    "    \"\"\"\n",
    "    context = tf.reduce_sum(contexts * tf.expand_dims(alpha,2), axis = 1) # after shape 32 * 512\n",
    "    \n",
    "    tiled_masks = tf.tile(tf.expand_dims(masks[:, idx], 1),\n",
    "                          [1, 196])\n",
    "    masked_alpha = alpha * tiled_masks\n",
    "    alphas.append(tf.reshape(masked_alpha, [-1]))\n",
    "    \n",
    "  # Embed the last word\n",
    "  with tf.variable_scope(\"word_embedding\"):\n",
    "    word_embed = tf.nn.embedding_lookup(embedding_matrix,\n",
    "                                          last_word)\n",
    "  \n",
    "  # Apply the LSTM\n",
    "  \"\"\"\n",
    "  將上一個字和context\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\"lstm\"):\n",
    "    current_input = tf.concat([context, word_embed], 1)\n",
    "    output, state = lstm(current_input, last_state)\n",
    "    memory, _ = state\n",
    "\n",
    "  # Decode the expanded output of LSTM into a word\n",
    "  with tf.variable_scope(\"decode\", reuse=tf.AUTO_REUSE) as de_scope:\n",
    "#       de_scope.reuse_variables()\n",
    "    expanded_output = tf.concat([output,\n",
    "                                   context,\n",
    "                                   word_embed],\n",
    "                                  axis=1)\n",
    "    logits = decode(expanded_output)\n",
    "    probs = tf.nn.softmax(logits)\n",
    "\n",
    "    prediction = tf.argmax(logits, 1)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "          labels=sentences[:, idx],\n",
    "          logits=logits)\n",
    "    masked_cross_entropy = cross_entropy * masks[:, idx]\n",
    "    cross_entropies.append(masked_cross_entropy)\n",
    "\n",
    "    ground_truth = tf.cast(sentences[:, idx], tf.int64)\n",
    "    prediction_correct = tf.where(\n",
    "          tf.equal(prediction, ground_truth),\n",
    "          tf.cast(masks[:, idx], tf.float32),\n",
    "          tf.cast(tf.zeros_like(prediction), tf.float32))\n",
    "    predictions_correct.append(prediction_correct)\n",
    "\n",
    "    last_output = output\n",
    "    last_memory = memory\n",
    "    last_state = state\n",
    "    last_word = sentences[:, idx]\n",
    "\n",
    "    tf.get_variable_scope().reuse_variables() \n",
    "    cross_entropies = tf.stack(cross_entropies, axis=1)\n",
    "    cross_entropy_loss = tf.reduce_sum(cross_entropies) / tf.reduce_sum(masks)\n",
    "\n",
    "    alphas = tf.stack(alphas, axis=1)\n",
    "    alphas = tf.reshape(alphas, [batch_size, num_ctx, -1])\n",
    "    attentions = tf.reduce_sum(alphas, axis=2)\n",
    "    diffs = tf.ones_like(attentions) - attentions\n",
    "    attention_loss = attention_loss_factor \\\n",
    "                 * tf.nn.l2_loss(diffs) \\\n",
    "                 / (batch_size * num_ctx)\n",
    "\n",
    "    reg_loss = tf.losses.get_regularization_loss()\n",
    "\n",
    "    total_loss = cross_entropy_loss + attention_loss + reg_loss\n",
    "\n",
    "    predictions_correct = tf.stack(predictions_correct, axis=1)\n",
    "    accuracy = tf.reduce_sum(predictions_correct) \\\n",
    "           / tf.reduce_sum(masks)\n",
    "    \n",
    "    contexts = contexts\n",
    "\n",
    "    sentences = sentences\n",
    "    masks = masks\n",
    "    total_loss = total_loss\n",
    "    cross_entropy_loss = cross_entropy_loss\n",
    "    attention_loss = attention_loss\n",
    "    reg_loss = reg_loss\n",
    "    accuracy = accuracy\n",
    "    attentions = attentions\n",
    "\n",
    "    initial_memory = initial_memory\n",
    "    initial_output = initial_output\n",
    "    last_memory = last_memory\n",
    "    last_output = last_output\n",
    "    last_word = last_word\n",
    "    memory = memory\n",
    "    output = output\n",
    "    probs = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dir = './summary/'\n",
    "num_epochs = 100\n",
    "num_batches = 32\n",
    "\n",
    "def train(sess, train_data):\n",
    "    if not os.path.exists(summary_dir):\n",
    "        os.mkdir(summary_dir)\n",
    "        train_writer = tf.summary.FileWriter(summary_dir,\n",
    "                                             sess.graph)\n",
    "        for _ in tqdm(list(range(num_epochs)), desc='epoch'):\n",
    "            for _ in tqdm(list(range(train_data.num_batches)), desc='batch'):\n",
    "                batch = train_data.next_batch()\n",
    "                image_files, sentences, masks = batch\n",
    "                images = self.image_loader.load_images(image_files)\n",
    "                feed_dict = {self.images: images,\n",
    "                             self.sentences: sentences,\n",
    "                             self.masks: masks}\n",
    "                _, summary, global_step = sess.run([self.opt_op,\n",
    "                                                    self.summary,\n",
    "                                                    self.global_step],\n",
    "                                                    feed_dict=feed_dict)\n",
    "                if (global_step + 1) % config.save_period == 0:\n",
    "                    self.save()\n",
    "                train_writer.add_summary(summary, global_step)\n",
    "            train_data.reset()\n",
    "\n",
    "        self.save()\n",
    "        train_writer.close()\n",
    "        print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "#     data = prepare_train_data(config)\n",
    "    model = CaptionGenerator(config)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "#     if FLAGS.load:\n",
    "#         model.load(sess, FLAGS.model_file)\n",
    "#     if FLAGS.load_cnn:\n",
    "#         model.load_cnn(sess, FLAGS.cnn_model_file)\n",
    "    tf.get_default_graph().finalize()\n",
    "    model.train(sess, data)\n",
    "    coco, data_reward, vocabulary = data_for_reward(config)\n",
    "    model.train_eval(sess, coco, data_reward, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
